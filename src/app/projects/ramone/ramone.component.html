<div class="text-container read">
    <article class="read-wrap">
        <h1 style="animation: transitionIn 0.75s; font-size: 58px; display: flex; justify-content: center;">
            <div>Ramone</div>
        </h1>
        <div class="img-container" style="animation: transitionIn 1.5s; margin-top: 20px;">
            <img src="../../../assets/pictures/ramone.jpeg">
        </div>
        <div class="p-content" data-aos="zoom-in-up">
            <h3>
                Ramone was my first year university group project. It is based on a Raspberry Pi and the software is
                written
                in Python.
                <br>
                <br>
                Our goal was to create a robot that some what simulates a real self-driving car. We then turned this
                idea into lane following for simplicity purposes.
                <br>
                <br>
                Basically we create the "roads" by sticking green painter's tape on the ground. Ramone is able to
                navigate itself within the road that the tapes created. Ramone manages some of the complicated road
                patterns like the "8" and crosses pretty well. Here is a demo video.
            </h3>
        </div>
        <div class="img-container" data-aos="zoom-in-down">
            <video width="1000" height="600" controls="controls" muted="true">
                <source src="../../../assets/videos/EPIC.mp4" type="video/mp4">
            </video>
        </div>
    </article>
</div>

<div class="text-container read" style="background-color: #A2978F; margin-top: 30px;" data-aos="zoom-in-up">
    <article class="read-wrap">
        <h3 class="p-content" data-aos="zoom-in-up">
            The whole visioning and navigation is implemented with OpenCV. It was kind of hard for me to wrap my head
            around Python (this project was the first time I touched python). Just the installation itself was causing
            me lots of troubles already.
            <br>
            <br> After I got somewhat used to Git and Python, I started working on my task. The whole projects consists
            lots of different algorithms and components, like pure-persuit following, color-recongnizing, distance
            calculation, calibration, etc.
            <br>
            <br> I mainly worked on the color/lane recongnizing algorithm with one of my teamates, the algorithm is
            explained in the demo video
            <br>
            <br> One thing I forgot to mention is the whole color recongnizing thing is pretty straightforward. Convert
            the frame's RGB color into HSV (OpenCV needed HSV), and then apply a mask onto the frame. The mask will
            convert any color besides green to black, and display green as white, so then we can get the correct pixels
            and start
            working on the distance/lane following algorithm.
            <br>
            <br> Here is a video of us debugging, I thought it looked really cool. I mean, as someone who had never seen
            an actual Linux os in use, I thought anything, even a
            command window popping up in Linux was really cool at that point.
        </h3>
        <div class="img-container" data-aos="zoom-in-down">
            <video width="1000" height="600" controls="controls" muted="true">
                <source src="../../../assets/videos/20191129_192243.mp4" type="video/mp4">
            </video>
        </div>
    </article>
</div>

<script>
    AOS.init()
</script>